/**
 * OCR æ¨¡å—
 * æ”¯æŒå¤šç§ OCR åç«¯:
 * 1. PaddleOCR (æœ¬åœ°è½»é‡çº§ ONNX æ¨¡å‹)
 * 2. å¤§æ¨¡å‹è§†è§‰ API (Gemini/Claude/GPT-4V)
 * 3. ç³»ç»ŸåŸç”Ÿ OCR (macOS Vision, Windows OCR)
 */

import { EventEmitter } from 'events';

// ============ ç±»å‹å®šä¹‰ ============

export interface OCRConfig {
  /** OCR åç«¯ç±»å‹ */
  backend: OCRBackend;
  /** è¯†åˆ«è¯­è¨€ */
  languages: string[];
  /** ç½®ä¿¡åº¦é˜ˆå€¼ (0-1) */
  confidenceThreshold: number;
  /** æ˜¯å¦å¯ç”¨ GPU åŠ é€Ÿ */
  useGPU: boolean;
}

export type OCRBackend =
  | 'paddle'      // PaddleOCR (æ¨èï¼Œè½»é‡çº§æœ¬åœ°)
  | 'vision-api'  // å¤§æ¨¡å‹è§†è§‰ API
  | 'system'      // ç³»ç»ŸåŸç”Ÿ OCR
  | 'auto';       // è‡ªåŠ¨é€‰æ‹©æœ€ä½³åç«¯

export interface OCRResult {
  /** è¯†åˆ«çš„å…¨éƒ¨æ–‡æœ¬ */
  text: string;
  /** ç½®ä¿¡åº¦ (0-100) */
  confidence: number;
  /** æ–‡æœ¬åŒºåŸŸ */
  regions: OCRRegion[];
  /** å¤„ç†è€—æ—¶ (ms) */
  duration: number;
  /** ä½¿ç”¨çš„åç«¯ */
  backend: OCRBackend;
}

export interface OCRRegion {
  /** æ–‡æœ¬å†…å®¹ */
  text: string;
  /** ç½®ä¿¡åº¦ */
  confidence: number;
  /** è¾¹ç•Œæ¡† [x, y, width, height] */
  bbox: [number, number, number, number];
  /** å¤šè¾¹å½¢é¡¶ç‚¹ï¼ˆå¦‚æœå¯ç”¨ï¼‰*/
  polygon?: [number, number][];
}

// ============ OCR åç«¯æ¥å£ ============

export interface IOCRBackend {
  readonly name: string;
  readonly isAvailable: boolean;

  initialize(): Promise<void>;
  recognize(imageData: string | Buffer): Promise<OCRResult>;
  terminate(): Promise<void>;
}

// ============ PaddleOCR åç«¯ ============

/**
 * PaddleOCR åç«¯
 *
 * æ”¯æŒå¤šç§å®‰è£…æ–¹å¼:
 * 1. @paddlejs-models/ocr (å®˜æ–¹ Paddle.jsï¼Œæµè§ˆå™¨/Node.js)
 * 2. paddleocr (Python ç‰ˆï¼Œé€šè¿‡ child_process è°ƒç”¨)
 * 3. PaddleOCR MCP Server (å¯é›†æˆåˆ° Claude Desktop)
 *
 * è½»é‡çº§ï¼Œæ”¯æŒ 100+ è¯­è¨€ï¼Œå®Œå…¨æœ¬åœ°è¿è¡Œ
 * å®˜æ–¹æ–‡æ¡£: https://github.com/PaddlePaddle/PaddleOCR
 */
export class PaddleOCRBackend implements IOCRBackend {
  readonly name = 'paddle';
  private ocr: any = null;
  private config: OCRConfig;
  private mode: 'paddlejs' | 'python' | 'none' = 'none';

  constructor(config: OCRConfig) {
    this.config = config;
  }

  get isAvailable(): boolean {
    return this.mode !== 'none';
  }

  async initialize(): Promise<void> {
    // æ–¹å¼ 1: å°è¯•ä½¿ç”¨å®˜æ–¹ @paddlejs-models/ocr
    try {
      const PaddleJS = await import('@paddlejs-models/ocr').catch(() => null);
      if (PaddleJS) {
        this.ocr = PaddleJS;
        await this.ocr.init();
        this.mode = 'paddlejs';
        console.log('âœ“ ä½¿ç”¨ Paddle.js OCR (å®˜æ–¹ JavaScript ç‰ˆæœ¬)');
        return;
      }
    } catch {
      // ç»§ç»­å°è¯•å…¶ä»–æ–¹å¼
    }

    // æ–¹å¼ 2: å°è¯•é€šè¿‡ Python è°ƒç”¨ paddleocr
    try {
      const { execSync } = await import('child_process');
      // æ£€æŸ¥ paddleocr æ˜¯å¦å®‰è£…
      execSync('python -c "import paddleocr"', { stdio: 'ignore' });
      this.mode = 'python';
      console.log('âœ“ ä½¿ç”¨ PaddleOCR Python ç‰ˆæœ¬');
      return;
    } catch {
      // Python ç‰ˆæœ¬ä¸å¯ç”¨
    }

    throw new Error(
      'PaddleOCR æœªå®‰è£…ã€‚è¯·é€‰æ‹©ä»¥ä¸‹æ–¹å¼ä¹‹ä¸€:\n' +
      '1. npm install @paddlejs-models/ocr (æ¨èï¼ŒJavaScript ç‰ˆæœ¬)\n' +
      '2. pip install paddleocr (Python ç‰ˆæœ¬)'
    );
  }

  async recognize(imageData: string | Buffer): Promise<OCRResult> {
    const startTime = Date.now();

    if (this.mode === 'paddlejs') {
      return this.recognizeWithPaddleJS(imageData, startTime);
    } else if (this.mode === 'python') {
      return this.recognizeWithPython(imageData, startTime);
    }

    throw new Error('PaddleOCR æœªåˆå§‹åŒ–');
  }

  private async recognizeWithPaddleJS(
    imageData: string | Buffer,
    startTime: number
  ): Promise<OCRResult> {
    // Paddle.js éœ€è¦ Canvas/Imageï¼Œåœ¨ Node.js ç¯å¢ƒéœ€è¦ node-canvas
    const base64 = typeof imageData === 'string'
      ? imageData
      : imageData.toString('base64');

    // åˆ›å»º Image å¯¹è±¡ï¼ˆéœ€è¦ node-canvas æˆ–åœ¨æµè§ˆå™¨ç¯å¢ƒï¼‰
    const result = await this.ocr.recognize(base64);

    const regions: OCRRegion[] = (result || []).map((item: any) => ({
      text: item.text || '',
      confidence: (item.confidence || 0) * 100,
      bbox: item.box ? [
        Math.min(...item.box.map((p: number[]) => p[0])),
        Math.min(...item.box.map((p: number[]) => p[1])),
        Math.max(...item.box.map((p: number[]) => p[0])) - Math.min(...item.box.map((p: number[]) => p[0])),
        Math.max(...item.box.map((p: number[]) => p[1])) - Math.min(...item.box.map((p: number[]) => p[1])),
      ] as [number, number, number, number] : [0, 0, 0, 0],
      polygon: item.box,
    }));

    const fullText = regions.map(r => r.text).join('\n');
    const avgConfidence = regions.length > 0
      ? regions.reduce((sum, r) => sum + r.confidence, 0) / regions.length
      : 0;

    return {
      text: fullText,
      confidence: avgConfidence,
      regions,
      duration: Date.now() - startTime,
      backend: 'paddle',
    };
  }

  private async recognizeWithPython(
    imageData: string | Buffer,
    startTime: number
  ): Promise<OCRResult> {
    const { execSync } = await import('child_process');
    const { writeFileSync, unlinkSync, readFileSync } = await import('fs');
    const { join } = await import('path');
    const { tmpdir } = await import('os');

    const buffer = typeof imageData === 'string'
      ? Buffer.from(imageData, 'base64')
      : imageData;

    const inputPath = join(tmpdir(), `hawkeye_ocr_in_${Date.now()}.png`);
    const outputPath = join(tmpdir(), `hawkeye_ocr_out_${Date.now()}.json`);

    writeFileSync(inputPath, buffer);

    try {
      // è°ƒç”¨ PaddleOCR Python API
      const pythonScript = `
import json
from paddleocr import PaddleOCR

ocr = PaddleOCR(use_angle_cls=True, lang='ch', show_log=False)
result = ocr.ocr('${inputPath}', cls=True)

output = []
if result and result[0]:
    for line in result[0]:
        box, (text, confidence) = line
        output.append({
            'box': box,
            'text': text,
            'confidence': confidence
        })

with open('${outputPath}', 'w', encoding='utf-8') as f:
    json.dump(output, f, ensure_ascii=False)
`;

      execSync(`python -c "${pythonScript.replace(/"/g, '\\"').replace(/\n/g, ';')}"`, {
        timeout: 30000,
        encoding: 'utf-8',
      });

      const resultJson = JSON.parse(readFileSync(outputPath, 'utf-8'));

      const regions: OCRRegion[] = resultJson.map((item: any) => ({
        text: item.text,
        confidence: item.confidence * 100,
        bbox: [
          Math.min(...item.box.map((p: number[]) => p[0])),
          Math.min(...item.box.map((p: number[]) => p[1])),
          Math.max(...item.box.map((p: number[]) => p[0])) - Math.min(...item.box.map((p: number[]) => p[0])),
          Math.max(...item.box.map((p: number[]) => p[1])) - Math.min(...item.box.map((p: number[]) => p[1])),
        ] as [number, number, number, number],
        polygon: item.box,
      }));

      const fullText = regions.map(r => r.text).join('\n');
      const avgConfidence = regions.length > 0
        ? regions.reduce((sum, r) => sum + r.confidence, 0) / regions.length
        : 0;

      return {
        text: fullText,
        confidence: avgConfidence,
        regions,
        duration: Date.now() - startTime,
        backend: 'paddle',
      };
    } finally {
      try { unlinkSync(inputPath); } catch {}
      try { unlinkSync(outputPath); } catch {}
    }
  }

  async terminate(): Promise<void> {
    this.ocr = null;
    this.mode = 'none';
  }
}

// ============ ç³»ç»ŸåŸç”Ÿ OCR åç«¯ ============

/**
 * ç³»ç»ŸåŸç”Ÿ OCR (macOS Vision / Windows OCR)
 * é›¶ä¾èµ–ï¼Œä½¿ç”¨ç³»ç»Ÿå†…ç½®çš„ OCR èƒ½åŠ›
 */
export class SystemOCRBackend implements IOCRBackend {
  readonly name = 'system';
  private platform: NodeJS.Platform;
  private initialized: boolean = false;

  constructor() {
    this.platform = process.platform;
  }

  get isAvailable(): boolean {
    return this.platform === 'darwin' || this.platform === 'win32';
  }

  async initialize(): Promise<void> {
    if (!this.isAvailable) {
      throw new Error(`ç³»ç»Ÿ OCR ä¸æ”¯æŒ ${this.platform} å¹³å°`);
    }

    // åœ¨ macOS ä¸ŠéªŒè¯ swift æ˜¯å¦å¯ç”¨
    if (this.platform === 'darwin') {
      try {
        const { execSync } = await import('child_process');
        execSync('which swift', { stdio: 'ignore' });
        console.log('[OCR] âœ“ macOS Vision OCR å¯ç”¨ (swift found)');
      } catch {
        throw new Error('macOS ç³»ç»Ÿ OCR éœ€è¦ Swift å‘½ä»¤è¡Œå·¥å…·');
      }
    }

    this.initialized = true;
  }

  async recognize(imageData: string | Buffer): Promise<OCRResult> {
    const startTime = Date.now();

    const buffer = typeof imageData === 'string'
      ? Buffer.from(imageData, 'base64')
      : imageData;

    let result: { text: string; confidence: number };

    if (this.platform === 'darwin') {
      result = await this.recognizeMacOS(buffer);
    } else if (this.platform === 'win32') {
      result = await this.recognizeWindows(buffer);
    } else {
      throw new Error(`ç³»ç»Ÿ OCR ä¸æ”¯æŒ ${this.platform} å¹³å°`);
    }

    return {
      text: result.text,
      confidence: result.confidence,
      regions: [{
        text: result.text,
        confidence: result.confidence,
        bbox: [0, 0, 0, 0],
      }],
      duration: Date.now() - startTime,
      backend: 'system',
    };
  }

  private async recognizeMacOS(imageBuffer: Buffer): Promise<{ text: string; confidence: number }> {
    const { writeFileSync, unlinkSync, existsSync, readFileSync } = await import('fs');
    const { join } = await import('path');
    const { tmpdir } = await import('os');

    const timestamp = Date.now();
    const tempImagePath = join(tmpdir(), `hawkeye_ocr_${timestamp}.png`);
    const tempOutputPath = join(tmpdir(), `hawkeye_ocr_${timestamp}.txt`);

    // ä¿å­˜å›¾ç‰‡ä¸´æ—¶æ–‡ä»¶
    writeFileSync(tempImagePath, imageBuffer);

    try {
      const OCR_TIMEOUT = 30000; // 30 ç§’è¶…æ—¶

      // æ–¹æ¡ˆ 1: ä½¿ç”¨ Swift è°ƒç”¨ Vision Framework (æœ€å¯é )
      const swiftResult = await this.runSwiftVisionOCR(tempImagePath, tempOutputPath, OCR_TIMEOUT);

      if (swiftResult.success && existsSync(tempOutputPath)) {
        const text = readFileSync(tempOutputPath, 'utf-8').trim();
        console.log(`[OCR] âœ“ macOS Vision OCR æˆåŠŸï¼Œè¯†åˆ« ${text.length} å­—ç¬¦`);
        return { text, confidence: 90 };  // 90% confidence for Vision Framework results
      }

      // Swift æ–¹æ¡ˆå¤±è´¥ï¼Œè¯¦ç»†è®°å½•é”™è¯¯
      console.warn(`[OCR] âš ï¸ Swift Vision OCR å¤±è´¥`);
      if (swiftResult.error) {
        console.warn(`[OCR] é”™è¯¯è¯¦æƒ…: ${swiftResult.error.slice(0, 500)}`);
      }
      console.warn(`[OCR] ä¸´æ—¶å›¾ç‰‡è·¯å¾„: ${tempImagePath}`);
      console.warn(`[OCR] è¾“å‡ºæ–‡ä»¶è·¯å¾„: ${tempOutputPath}`);
      console.warn(`[OCR] è¾“å‡ºæ–‡ä»¶å­˜åœ¨: ${existsSync(tempOutputPath)}`);

      // è¿”å›ç©ºç»“æœï¼Œè®©è°ƒç”¨æ–¹å›é€€åˆ° Vision API
      console.log('[OCR] macOS ç³»ç»Ÿ OCR å¤±è´¥ï¼Œå°†å›é€€åˆ° Vision APIï¼ˆå¦‚å·²é…ç½®ï¼‰');
      return { text: '', confidence: 0 };
    } catch (error: any) {
      console.warn('[OCR] macOS Vision OCR failed:', error.message?.slice(0, 200));
      return { text: '', confidence: 0 };
    } finally {
      // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
      try { if (existsSync(tempImagePath)) unlinkSync(tempImagePath); } catch {}
      try { if (existsSync(tempOutputPath)) unlinkSync(tempOutputPath); } catch {}
    }
  }

  /**
   * ä½¿ç”¨ Swift è°ƒç”¨ Vision Framework è¿›è¡Œ OCR
   * Swift æ–¹å¼æ¯” AppleScriptObjC æ›´å¯é ï¼Œå…¼å®¹æ€§æ›´å¥½
   * æ”¹è¿›ï¼šå°† Swift ä»£ç å†™å…¥æ–‡ä»¶æ‰§è¡Œï¼Œæ¯” -e æ›´å¯é 
   */
  private async runSwiftVisionOCR(
    imagePath: string,
    outputPath: string,
    timeout: number
  ): Promise<{ success: boolean; error?: string }> {
    const { spawn } = await import('child_process');
    const { writeFileSync, unlinkSync, existsSync } = await import('fs');
    const { join } = await import('path');
    const { tmpdir } = await import('os');

    // åˆ›å»ºä¸´æ—¶ Swift è„šæœ¬æ–‡ä»¶
    const timestamp = Date.now();
    const swiftScriptPath = join(tmpdir(), `hawkeye_ocr_${timestamp}.swift`);

    // Swift ä»£ç  - ä½¿ç”¨ Vision Framework è¿›è¡Œæ–‡æœ¬è¯†åˆ«
    const swiftCode = `
import Foundation
import Vision
import AppKit

let imagePath = "${imagePath}"
let outputPath = "${outputPath}"

// è¾“å‡ºè°ƒè¯•ä¿¡æ¯
fputs("[Swift] å¼€å§‹ Vision OCR...\\n", stderr)
fputs("[Swift] å›¾ç‰‡è·¯å¾„: \\(imagePath)\\n", stderr)

guard let image = NSImage(contentsOfFile: imagePath) else {
    fputs("[Swift] Error: Cannot load image from path\\n", stderr)
    exit(1)
}

guard let cgImage = image.cgImage(forProposedRect: nil, context: nil, hints: nil) else {
    fputs("[Swift] Error: Cannot convert to CGImage\\n", stderr)
    exit(1)
}

fputs("[Swift] å›¾ç‰‡åŠ è½½æˆåŠŸï¼Œå°ºå¯¸: \\(Int(image.size.width))x\\(Int(image.size.height))\\n", stderr)

let request = VNRecognizeTextRequest()
request.recognitionLevel = .accurate
request.recognitionLanguages = ["zh-Hans", "zh-Hant", "en-US", "ja"]
request.usesLanguageCorrection = true

let handler = VNImageRequestHandler(cgImage: cgImage, options: [:])

do {
    fputs("[Swift] æ‰§è¡Œæ–‡æœ¬è¯†åˆ«è¯·æ±‚...\\n", stderr)
    try handler.perform([request])
} catch {
    fputs("[Swift] Error performing request: \\(error.localizedDescription)\\n", stderr)
    exit(1)
}

var recognizedText = ""
if let observations = request.results {
    fputs("[Swift] è¯†åˆ«åˆ° \\(observations.count) ä¸ªæ–‡æœ¬åŒºåŸŸ\\n", stderr)
    for observation in observations {
        if let topCandidate = observation.topCandidates(1).first {
            recognizedText += topCandidate.string + "\\n"
        }
    }
}

fputs("[Swift] è¯†åˆ«å®Œæˆï¼Œæ–‡æœ¬é•¿åº¦: \\(recognizedText.count) å­—ç¬¦\\n", stderr)

do {
    try recognizedText.write(toFile: outputPath, atomically: true, encoding: .utf8)
    fputs("[Swift] ç»“æœå·²å†™å…¥: \\(outputPath)\\n", stderr)
} catch {
    fputs("[Swift] Error writing output: \\(error.localizedDescription)\\n", stderr)
    exit(1)
}
`;

    try {
      // å†™å…¥ Swift è„šæœ¬æ–‡ä»¶
      writeFileSync(swiftScriptPath, swiftCode);
      console.log(`[OCR] Swift è„šæœ¬å·²å†™å…¥: ${swiftScriptPath}`);

      return new Promise((resolve) => {
        let resolved = false;
        let stderr = '';
        let stdout = '';

        // ä½¿ç”¨ swift å‘½ä»¤æ‰§è¡Œè„šæœ¬æ–‡ä»¶ï¼ˆæ¯” -e æ›´å¯é ï¼‰
        const proc = spawn('swift', [swiftScriptPath], {
          stdio: ['ignore', 'pipe', 'pipe'],
          env: { ...process.env, LANG: 'en_US.UTF-8' },
        });

        // è®¾ç½®è¶…æ—¶å®šæ—¶å™¨
        const timeoutId = setTimeout(() => {
          if (!resolved) {
            resolved = true;
            console.warn(`[OCR] Swift Vision OCR è¶…æ—¶ (${timeout}ms)ï¼Œå¼ºåˆ¶ç»ˆæ­¢è¿›ç¨‹`);
            proc.kill('SIGKILL');
            resolve({ success: false, error: `Timeout after ${timeout}ms` });
          }
        }, timeout);

        proc.stdout?.on('data', (data) => {
          stdout += data.toString();
        });

        proc.stderr?.on('data', (data) => {
          const msg = data.toString();
          stderr += msg;
          // è¾“å‡º Swift è°ƒè¯•ä¿¡æ¯
          if (msg.includes('[Swift]')) {
            console.log(`[OCR] ${msg.trim()}`);
          }
        });

        proc.on('close', (code) => {
          if (!resolved) {
            resolved = true;
            clearTimeout(timeoutId);
            // æ¸…ç† Swift è„šæœ¬æ–‡ä»¶
            try { if (existsSync(swiftScriptPath)) unlinkSync(swiftScriptPath); } catch {}

            if (code === 0) {
              console.log(`[OCR] Swift è¿›ç¨‹æˆåŠŸé€€å‡º`);
              resolve({ success: true });
            } else {
              console.warn(`[OCR] Swift è¿›ç¨‹é€€å‡ºç : ${code}`);
              console.warn(`[OCR] Swift stderr: ${stderr.slice(0, 500)}`);
              resolve({ success: false, error: stderr || `Exit code: ${code}` });
            }
          }
        });

        proc.on('error', (error) => {
          if (!resolved) {
            resolved = true;
            clearTimeout(timeoutId);
            // æ¸…ç† Swift è„šæœ¬æ–‡ä»¶
            try { if (existsSync(swiftScriptPath)) unlinkSync(swiftScriptPath); } catch {}
            console.warn(`[OCR] Swift è¿›ç¨‹é”™è¯¯: ${error.message}`);
            resolve({ success: false, error: error.message });
          }
        });
      });
    } catch (err: any) {
      // æ¸…ç† Swift è„šæœ¬æ–‡ä»¶
      try { if (existsSync(swiftScriptPath)) unlinkSync(swiftScriptPath); } catch {}
      return { success: false, error: err.message };
    }
  }

  private async recognizeWindows(imageBuffer: Buffer): Promise<{ text: string; confidence: number }> {
    const { execSync } = await import('child_process');
    const { writeFileSync, unlinkSync } = await import('fs');
    const { join } = await import('path');
    const { tmpdir } = await import('os');

    const tempPath = join(tmpdir(), `hawkeye_ocr_${Date.now()}.png`);
    writeFileSync(tempPath, imageBuffer);

    try {
      // ä½¿ç”¨ Windows OCR API (é€šè¿‡ PowerShell)
      const script = `
        Add-Type -AssemblyName System.Runtime.WindowsRuntime
        $null = [Windows.Media.Ocr.OcrEngine, Windows.Foundation, ContentType=WindowsRuntime]
        $null = [Windows.Graphics.Imaging.BitmapDecoder, Windows.Foundation, ContentType=WindowsRuntime]

        $file = [Windows.Storage.StorageFile]::GetFileFromPathAsync("${tempPath.replace(/\\/g, '\\\\')}").GetAwaiter().GetResult()
        $stream = $file.OpenAsync([Windows.Storage.FileAccessMode]::Read).GetAwaiter().GetResult()
        $decoder = [Windows.Graphics.Imaging.BitmapDecoder]::CreateAsync($stream).GetAwaiter().GetResult()
        $bitmap = $decoder.GetSoftwareBitmapAsync().GetAwaiter().GetResult()

        $engine = [Windows.Media.Ocr.OcrEngine]::TryCreateFromUserProfileLanguages()
        $result = $engine.RecognizeAsync($bitmap).GetAwaiter().GetResult()

        Write-Output $result.Text
      `;

      const result = execSync(`powershell -Command "${script}"`, {
        encoding: 'utf-8',
        timeout: 30000,
      });

      return { text: result.trim(), confidence: 0.85 };
    } catch {
      return { text: '', confidence: 0 };
    } finally {
      try { unlinkSync(tempPath); } catch {}
    }
  }

  async terminate(): Promise<void> {
    // æ— éœ€æ¸…ç†
  }
}

// ============ å¤§æ¨¡å‹è§†è§‰ API åç«¯ ============

/**
 * å¤§æ¨¡å‹è§†è§‰ API åç«¯
 * ä½¿ç”¨ Gemini/Claude/GPT-4V ç­‰å¤§æ¨¡å‹çš„è§†è§‰èƒ½åŠ›
 * éœ€è¦åœ¨ AI Manager ä¸­é…ç½® API
 */
export class VisionAPIBackend implements IOCRBackend {
  readonly name = 'vision-api';
  private analyzeFunction: ((imageBase64: string) => Promise<string>) | null = null;

  get isAvailable(): boolean {
    return this.analyzeFunction !== null;
  }

  /**
   * è®¾ç½®åˆ†æå‡½æ•°ï¼ˆç”± AI Manager æ³¨å…¥ï¼‰
   */
  setAnalyzeFunction(fn: (imageBase64: string) => Promise<string>): void {
    this.analyzeFunction = fn;
  }

  async initialize(): Promise<void> {
    if (!this.analyzeFunction) {
      throw new Error('Vision API æœªé…ç½®ã€‚è¯·å…ˆè®¾ç½® AI Managerã€‚');
    }
  }

  async recognize(imageData: string | Buffer): Promise<OCRResult> {
    if (!this.analyzeFunction) {
      throw new Error('Vision API æœªé…ç½®');
    }

    const startTime = Date.now();

    const base64 = typeof imageData === 'string'
      ? imageData
      : imageData.toString('base64');

    const text = await this.analyzeFunction(base64);

    return {
      text,
      confidence: 0.95,  // å¤§æ¨¡å‹é€šå¸¸å¾ˆå‡†ç¡®
      regions: [{
        text,
        confidence: 0.95,
        bbox: [0, 0, 0, 0],
      }],
      duration: Date.now() - startTime,
      backend: 'vision-api',
    };
  }

  async terminate(): Promise<void> {
    this.analyzeFunction = null;
  }
}

// ============ OCR ç®¡ç†å™¨ ============

export class OCRManager extends EventEmitter {
  private config: OCRConfig;
  private backends: Map<OCRBackend, IOCRBackend> = new Map();
  private activeBackend: IOCRBackend | null = null;

  constructor(config: Partial<OCRConfig> = {}) {
    super();
    this.config = {
      backend: 'auto',
      languages: ['zh-Hans', 'zh-Hant', 'en'],
      confidenceThreshold: 0.5,
      useGPU: false,
      ...config,
    };
  }

  /**
   * åˆå§‹åŒ– OCR
   */
  async initialize(): Promise<void> {
    // æ³¨å†Œæ‰€æœ‰åç«¯
    this.backends.set('paddle', new PaddleOCRBackend(this.config));
    this.backends.set('system', new SystemOCRBackend());
    this.backends.set('vision-api', new VisionAPIBackend());

    // é€‰æ‹©åç«¯
    if (this.config.backend === 'auto') {
      await this.autoSelectBackend();
    } else {
      await this.selectBackend(this.config.backend);
    }

    this.emit('initialized', this.activeBackend?.name);
  }

  /**
   * è‡ªåŠ¨é€‰æ‹©æœ€ä½³åç«¯
   * ä¼˜å…ˆçº§: Vision API > ç³»ç»Ÿ OCR > PaddleOCR
   * Vision API ä½¿ç”¨å·²é…ç½®çš„äº‘ç«¯ AIï¼Œæœ€ç¨³å®šå¯é 
   */
  private async autoSelectBackend(): Promise<void> {
    // ä¼˜å…ˆä½¿ç”¨ç³»ç»Ÿ OCRï¼ˆmacOS Vision / Windows OCRï¼‰- å…è´¹ã€å¿«é€Ÿã€ç¦»çº¿
    // å…¶æ¬¡ä½¿ç”¨ Vision APIï¼ˆæ¶ˆè€— API é¢åº¦ï¼‰
    // æœ€åä½¿ç”¨ PaddleOCRï¼ˆéœ€è¦é¢å¤–å®‰è£…ï¼‰
    const priorities: OCRBackend[] = ['system', 'vision-api', 'paddle'];

    console.log('[OCR] å¼€å§‹è‡ªåŠ¨é€‰æ‹© OCR åç«¯...');

    for (const backend of priorities) {
      try {
        console.log(`[OCR] å°è¯•åç«¯: ${backend}`);
        await this.selectBackend(backend);
        console.log(`[OCR] âœ“ æˆåŠŸé€‰æ‹©åç«¯: ${backend}`);
        return;
      } catch (err: any) {
        console.log(`[OCR] âœ— åç«¯ ${backend} ä¸å¯ç”¨: ${err.message}`);
        continue;
      }
    }

    console.error('[OCR] âœ— æ²¡æœ‰å¯ç”¨çš„ OCR åç«¯');
    throw new Error('æ²¡æœ‰å¯ç”¨çš„ OCR åç«¯');
  }

  /**
   * é€‰æ‹©ç‰¹å®šåç«¯
   */
  async selectBackend(backend: OCRBackend): Promise<void> {
    if (backend === 'auto') {
      await this.autoSelectBackend();
      return;
    }

    const instance = this.backends.get(backend);
    if (!instance) {
      throw new Error(`æœªçŸ¥çš„ OCR åç«¯: ${backend}`);
    }

    await instance.initialize();
    this.activeBackend = instance;
    this.emit('backend-changed', backend);
  }

  /**
   * æ‰§è¡Œ OCR è¯†åˆ«
   */
  async recognize(imageData: string | Buffer): Promise<OCRResult> {
    if (!this.activeBackend) {
      throw new Error('OCR æœªåˆå§‹åŒ–');
    }

    // æ—¥å¿—ï¼šè¾“å…¥ä¿¡æ¯
    const inputSize = typeof imageData === 'string'
      ? imageData.length
      : imageData.length;
    const inputType = typeof imageData === 'string' ? 'base64' : 'buffer';
    const startTime = Date.now();

    console.log(`\n[OCR] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•`);
    console.log(`[OCR] ğŸ” å¼€å§‹ OCR è¯†åˆ«`);
    console.log(`[OCR] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`);
    console.log(`[OCR] æ—¶é—´: ${new Date().toISOString()}`);
    console.log(`[OCR] è¾“å…¥ç±»å‹: ${inputType}`);
    console.log(`[OCR] è¾“å…¥å¤§å°: ${(inputSize / 1024).toFixed(2)} KB`);
    console.log(`[OCR] ä½¿ç”¨åç«¯: ${this.activeBackend.name}`);
    console.log(`[OCR] ç½®ä¿¡åº¦é˜ˆå€¼: ${(this.config.confidenceThreshold * 100).toFixed(0)}%`);
    console.log(`[OCR] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`);
    console.log(`[OCR] ğŸ“¤ å‘é€å›¾ç‰‡æ•°æ®åˆ° ${this.activeBackend.name}...`);

    const result = await this.activeBackend.recognize(imageData);

    // è¿‡æ»¤ä½ç½®ä¿¡åº¦ç»“æœ
    const originalRegionCount = result.regions.length;
    result.regions = result.regions.filter(
      r => r.confidence >= this.config.confidenceThreshold * 100
    );
    const filteredCount = originalRegionCount - result.regions.length;

    // æ—¥å¿—ï¼šè¾“å‡ºä¿¡æ¯
    console.log(`[OCR] ğŸ“¥ æ”¶åˆ°è¯†åˆ«ç»“æœ`);
    console.log(`[OCR] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`);
    console.log(`[OCR] âœ… è¯†åˆ«å®Œæˆ`);
    console.log(`[OCR] æ€»è€—æ—¶: ${result.duration} ms`);
    console.log(`[OCR] å¹³å‡ç½®ä¿¡åº¦: ${result.confidence.toFixed(2)}%`);
    console.log(`[OCR] æ£€æµ‹åŒºåŸŸ: ${originalRegionCount} ä¸ª (è¿‡æ»¤å: ${result.regions.length} ä¸ª)`);
    if (filteredCount > 0) {
      console.log(`[OCR] ä½ç½®ä¿¡åº¦è¿‡æ»¤: ${filteredCount} ä¸ªåŒºåŸŸè¢«è¿‡æ»¤`);
    }
    console.log(`[OCR] æ–‡æœ¬æ€»é•¿åº¦: ${result.text.length} å­—ç¬¦`);
    console.log(`[OCR] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`);
    console.log(`[OCR] ğŸ“ è¯†åˆ«æ–‡æœ¬å†…å®¹:`);
    console.log(`[OCR] ${result.text.slice(0, 800)}${result.text.length > 800 ? '\n[OCR] ... (æ›´å¤šå†…å®¹å·²çœç•¥)' : ''}`);
    console.log(`[OCR] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n`);

    this.emit('recognized', result);
    return result;
  }

  /**
   * è®¾ç½® Vision API åˆ†æå‡½æ•°
   */
  setVisionAnalyzer(fn: (imageBase64: string) => Promise<string>): void {
    const visionBackend = this.backends.get('vision-api') as VisionAPIBackend;
    if (visionBackend) {
      visionBackend.setAnalyzeFunction(fn);
    }
  }

  /**
   * è·å–å½“å‰åç«¯
   */
  getCurrentBackend(): string | null {
    return this.activeBackend?.name ?? null;
  }

  /**
   * è·å–å¯ç”¨åç«¯åˆ—è¡¨
   */
  getAvailableBackends(): string[] {
    return [...this.backends.entries()]
      .filter(([_, backend]) => backend.isAvailable)
      .map(([name, _]) => name);
  }

  /**
   * æ¸…ç†èµ„æº
   */
  async terminate(): Promise<void> {
    for (const backend of this.backends.values()) {
      await backend.terminate();
    }
    this.backends.clear();
    this.activeBackend = null;
    this.emit('terminated');
  }
}

// å¯¼å‡ºé»˜è®¤å®ä¾‹
export const ocrManager = new OCRManager();
