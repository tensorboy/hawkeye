/**
 * OCR æ¨¡å—
 * æ”¯æŒå¤šç§ OCR åç«¯:
 * 1. PaddleOCR (æœ¬åœ°è½»é‡çº§ ONNX æ¨¡å‹)
 * 2. å¤§æ¨¡å‹è§†è§‰ API (Gemini/Claude/GPT-4V)
 * 3. ç³»ç»ŸåŸç”Ÿ OCR (macOS Vision, Windows OCR)
 */

import { EventEmitter } from 'events';

// ============ ç±»å‹å®šä¹‰ ============

export interface OCRConfig {
  /** OCR åç«¯ç±»å‹ */
  backend: OCRBackend;
  /** è¯†åˆ«è¯­è¨€ */
  languages: string[];
  /** ç½®ä¿¡åº¦é˜ˆå€¼ (0-1) */
  confidenceThreshold: number;
  /** æ˜¯å¦å¯ç”¨ GPU åŠ é€Ÿ */
  useGPU: boolean;
}

export type OCRBackend =
  | 'paddle'      // PaddleOCR (æ¨èï¼Œè½»é‡çº§æœ¬åœ°)
  | 'vision-api'  // å¤§æ¨¡å‹è§†è§‰ API
  | 'system'      // ç³»ç»ŸåŸç”Ÿ OCR
  | 'auto';       // è‡ªåŠ¨é€‰æ‹©æœ€ä½³åç«¯

export interface OCRResult {
  /** è¯†åˆ«çš„å…¨éƒ¨æ–‡æœ¬ */
  text: string;
  /** ç½®ä¿¡åº¦ (0-100) */
  confidence: number;
  /** æ–‡æœ¬åŒºåŸŸ */
  regions: OCRRegion[];
  /** å¤„ç†è€—æ—¶ (ms) */
  duration: number;
  /** ä½¿ç”¨çš„åç«¯ */
  backend: OCRBackend;
}

export interface OCRRegion {
  /** æ–‡æœ¬å†…å®¹ */
  text: string;
  /** ç½®ä¿¡åº¦ */
  confidence: number;
  /** è¾¹ç•Œæ¡† [x, y, width, height] */
  bbox: [number, number, number, number];
  /** å¤šè¾¹å½¢é¡¶ç‚¹ï¼ˆå¦‚æœå¯ç”¨ï¼‰*/
  polygon?: [number, number][];
}

// ============ OCR åç«¯æ¥å£ ============

export interface IOCRBackend {
  readonly name: string;
  readonly isAvailable: boolean;

  initialize(): Promise<void>;
  recognize(imageData: string | Buffer): Promise<OCRResult>;
  terminate(): Promise<void>;
}

// ============ PaddleOCR åç«¯ ============

/**
 * PaddleOCR åç«¯
 *
 * æ”¯æŒå¤šç§å®‰è£…æ–¹å¼:
 * 1. @paddlejs-models/ocr (å®˜æ–¹ Paddle.jsï¼Œæµè§ˆå™¨/Node.js)
 * 2. paddleocr (Python ç‰ˆï¼Œé€šè¿‡ child_process è°ƒç”¨)
 * 3. PaddleOCR MCP Server (å¯é›†æˆåˆ° Claude Desktop)
 *
 * è½»é‡çº§ï¼Œæ”¯æŒ 100+ è¯­è¨€ï¼Œå®Œå…¨æœ¬åœ°è¿è¡Œ
 * å®˜æ–¹æ–‡æ¡£: https://github.com/PaddlePaddle/PaddleOCR
 */
export class PaddleOCRBackend implements IOCRBackend {
  readonly name = 'paddle';
  private ocr: any = null;
  private config: OCRConfig;
  private mode: 'paddlejs' | 'python' | 'none' = 'none';

  constructor(config: OCRConfig) {
    this.config = config;
  }

  get isAvailable(): boolean {
    return this.mode !== 'none';
  }

  async initialize(): Promise<void> {
    // æ–¹å¼ 1: å°è¯•ä½¿ç”¨å®˜æ–¹ @paddlejs-models/ocr
    try {
      const PaddleJS = await import('@paddlejs-models/ocr').catch(() => null);
      if (PaddleJS) {
        this.ocr = PaddleJS;
        await this.ocr.init();
        this.mode = 'paddlejs';
        console.log('âœ“ ä½¿ç”¨ Paddle.js OCR (å®˜æ–¹ JavaScript ç‰ˆæœ¬)');
        return;
      }
    } catch {
      // ç»§ç»­å°è¯•å…¶ä»–æ–¹å¼
    }

    // æ–¹å¼ 2: å°è¯•é€šè¿‡ Python è°ƒç”¨ paddleocr
    try {
      const { execSync } = await import('child_process');
      // æ£€æŸ¥ paddleocr æ˜¯å¦å®‰è£…
      execSync('python -c "import paddleocr"', { stdio: 'ignore' });
      this.mode = 'python';
      console.log('âœ“ ä½¿ç”¨ PaddleOCR Python ç‰ˆæœ¬');
      return;
    } catch {
      // Python ç‰ˆæœ¬ä¸å¯ç”¨
    }

    throw new Error(
      'PaddleOCR æœªå®‰è£…ã€‚è¯·é€‰æ‹©ä»¥ä¸‹æ–¹å¼ä¹‹ä¸€:\n' +
      '1. npm install @paddlejs-models/ocr (æ¨èï¼ŒJavaScript ç‰ˆæœ¬)\n' +
      '2. pip install paddleocr (Python ç‰ˆæœ¬)'
    );
  }

  async recognize(imageData: string | Buffer): Promise<OCRResult> {
    const startTime = Date.now();

    if (this.mode === 'paddlejs') {
      return this.recognizeWithPaddleJS(imageData, startTime);
    } else if (this.mode === 'python') {
      return this.recognizeWithPython(imageData, startTime);
    }

    throw new Error('PaddleOCR æœªåˆå§‹åŒ–');
  }

  private async recognizeWithPaddleJS(
    imageData: string | Buffer,
    startTime: number
  ): Promise<OCRResult> {
    // Paddle.js éœ€è¦ Canvas/Imageï¼Œåœ¨ Node.js ç¯å¢ƒéœ€è¦ node-canvas
    const base64 = typeof imageData === 'string'
      ? imageData
      : imageData.toString('base64');

    // åˆ›å»º Image å¯¹è±¡ï¼ˆéœ€è¦ node-canvas æˆ–åœ¨æµè§ˆå™¨ç¯å¢ƒï¼‰
    const result = await this.ocr.recognize(base64);

    const regions: OCRRegion[] = (result || []).map((item: any) => ({
      text: item.text || '',
      confidence: (item.confidence || 0) * 100,
      bbox: item.box ? [
        Math.min(...item.box.map((p: number[]) => p[0])),
        Math.min(...item.box.map((p: number[]) => p[1])),
        Math.max(...item.box.map((p: number[]) => p[0])) - Math.min(...item.box.map((p: number[]) => p[0])),
        Math.max(...item.box.map((p: number[]) => p[1])) - Math.min(...item.box.map((p: number[]) => p[1])),
      ] as [number, number, number, number] : [0, 0, 0, 0],
      polygon: item.box,
    }));

    const fullText = regions.map(r => r.text).join('\n');
    const avgConfidence = regions.length > 0
      ? regions.reduce((sum, r) => sum + r.confidence, 0) / regions.length
      : 0;

    return {
      text: fullText,
      confidence: avgConfidence,
      regions,
      duration: Date.now() - startTime,
      backend: 'paddle',
    };
  }

  private async recognizeWithPython(
    imageData: string | Buffer,
    startTime: number
  ): Promise<OCRResult> {
    const { execSync } = await import('child_process');
    const { writeFileSync, unlinkSync, readFileSync } = await import('fs');
    const { join } = await import('path');
    const { tmpdir } = await import('os');

    const buffer = typeof imageData === 'string'
      ? Buffer.from(imageData, 'base64')
      : imageData;

    const inputPath = join(tmpdir(), `hawkeye_ocr_in_${Date.now()}.png`);
    const outputPath = join(tmpdir(), `hawkeye_ocr_out_${Date.now()}.json`);

    writeFileSync(inputPath, buffer);

    try {
      // è°ƒç”¨ PaddleOCR Python API
      const pythonScript = `
import json
from paddleocr import PaddleOCR

ocr = PaddleOCR(use_angle_cls=True, lang='ch', show_log=False)
result = ocr.ocr('${inputPath}', cls=True)

output = []
if result and result[0]:
    for line in result[0]:
        box, (text, confidence) = line
        output.append({
            'box': box,
            'text': text,
            'confidence': confidence
        })

with open('${outputPath}', 'w', encoding='utf-8') as f:
    json.dump(output, f, ensure_ascii=False)
`;

      execSync(`python -c "${pythonScript.replace(/"/g, '\\"').replace(/\n/g, ';')}"`, {
        timeout: 30000,
        encoding: 'utf-8',
      });

      const resultJson = JSON.parse(readFileSync(outputPath, 'utf-8'));

      const regions: OCRRegion[] = resultJson.map((item: any) => ({
        text: item.text,
        confidence: item.confidence * 100,
        bbox: [
          Math.min(...item.box.map((p: number[]) => p[0])),
          Math.min(...item.box.map((p: number[]) => p[1])),
          Math.max(...item.box.map((p: number[]) => p[0])) - Math.min(...item.box.map((p: number[]) => p[0])),
          Math.max(...item.box.map((p: number[]) => p[1])) - Math.min(...item.box.map((p: number[]) => p[1])),
        ] as [number, number, number, number],
        polygon: item.box,
      }));

      const fullText = regions.map(r => r.text).join('\n');
      const avgConfidence = regions.length > 0
        ? regions.reduce((sum, r) => sum + r.confidence, 0) / regions.length
        : 0;

      return {
        text: fullText,
        confidence: avgConfidence,
        regions,
        duration: Date.now() - startTime,
        backend: 'paddle',
      };
    } finally {
      try { unlinkSync(inputPath); } catch {}
      try { unlinkSync(outputPath); } catch {}
    }
  }

  async terminate(): Promise<void> {
    this.ocr = null;
    this.mode = 'none';
  }
}

// ============ ç³»ç»ŸåŸç”Ÿ OCR åç«¯ ============

/**
 * ç³»ç»ŸåŸç”Ÿ OCR (macOS Vision / Windows OCR)
 * é›¶ä¾èµ–ï¼Œä½¿ç”¨ç³»ç»Ÿå†…ç½®çš„ OCR èƒ½åŠ›
 */
export class SystemOCRBackend implements IOCRBackend {
  readonly name = 'system';
  private platform: NodeJS.Platform;
  private initialized: boolean = false;

  constructor() {
    this.platform = process.platform;
  }

  get isAvailable(): boolean {
    return this.platform === 'darwin' || this.platform === 'win32';
  }

  async initialize(): Promise<void> {
    if (!this.isAvailable) {
      throw new Error(`ç³»ç»Ÿ OCR ä¸æ”¯æŒ ${this.platform} å¹³å°`);
    }

    // åœ¨ macOS ä¸ŠéªŒè¯ swift æ˜¯å¦å¯ç”¨
    if (this.platform === 'darwin') {
      try {
        const { execSync } = await import('child_process');
        execSync('which swift', { stdio: 'ignore' });
        console.log('[OCR] âœ“ macOS Vision OCR å¯ç”¨ (swift found)');
      } catch {
        throw new Error('macOS ç³»ç»Ÿ OCR éœ€è¦ Swift å‘½ä»¤è¡Œå·¥å…·');
      }
    }

    this.initialized = true;
  }

  async recognize(imageData: string | Buffer): Promise<OCRResult> {
    const startTime = Date.now();

    const buffer = typeof imageData === 'string'
      ? Buffer.from(imageData, 'base64')
      : imageData;

    let result: { text: string; confidence: number };

    if (this.platform === 'darwin') {
      result = await this.recognizeMacOS(buffer);
    } else if (this.platform === 'win32') {
      result = await this.recognizeWindows(buffer);
    } else {
      throw new Error(`ç³»ç»Ÿ OCR ä¸æ”¯æŒ ${this.platform} å¹³å°`);
    }

    return {
      text: result.text,
      confidence: result.confidence,
      regions: [{
        text: result.text,
        confidence: result.confidence,
        bbox: [0, 0, 0, 0],
      }],
      duration: Date.now() - startTime,
      backend: 'system',
    };
  }

  private async recognizeMacOS(imageBuffer: Buffer): Promise<{ text: string; confidence: number }> {
    const { exec, execSync } = await import('child_process');
    const { writeFileSync, unlinkSync, existsSync, readFileSync } = await import('fs');
    const { join } = await import('path');
    const { tmpdir } = await import('os');
    const { promisify } = await import('util');
    const execAsync = promisify(exec);

    const timestamp = Date.now();
    const tempImagePath = join(tmpdir(), `hawkeye_ocr_${timestamp}.png`);
    const tempOutputPath = join(tmpdir(), `hawkeye_ocr_${timestamp}.txt`);

    // ä¿å­˜å›¾ç‰‡ä¸´æ—¶æ–‡ä»¶
    writeFileSync(tempImagePath, imageBuffer);

    try {
      // æ–¹æ¡ˆ 1: ä½¿ç”¨ osascript è°ƒç”¨ Vision Framework (æœ€å¯é )
      // é€šè¿‡ AppleScript é—´æ¥è°ƒç”¨ï¼Œé¿å… Swift ç¼–è¯‘å»¶è¿Ÿ
      const appleScript = `
use framework "Vision"
use framework "Foundation"
use framework "AppKit"
use scripting additions

set imagePath to "${tempImagePath}"
set outputPath to "${tempOutputPath}"

set imageURL to current application's NSURL's fileURLWithPath:imagePath
set imageSource to current application's CGImageSourceCreateWithURL(imageURL, missing value)
set cgImage to current application's CGImageSourceCreateImageAtIndex(imageSource, 0, missing value)

set textRequest to current application's VNRecognizeTextRequest's alloc()'s init()
textRequest's setRecognitionLevel:(current application's VNRequestTextRecognitionLevelAccurate)
textRequest's setRecognitionLanguages:{"zh-Hans", "zh-Hant", "en-US", "ja"}
textRequest's setUsesLanguageCorrection:true

set requestHandler to current application's VNImageRequestHandler's alloc()'s initWithCGImage:cgImage options:(current application's NSDictionary's alloc()'s init())
requestHandler's performRequests:{textRequest} |error|:(missing value)

set recognizedText to ""
set observations to textRequest's results()
repeat with observation in observations
  set topCandidate to (observation's topCandidates:1)'s firstObject()
  if topCandidate is not missing value then
    set recognizedText to recognizedText & (topCandidate's |string|() as text) & linefeed
  end if
end repeat

-- å†™å…¥æ–‡ä»¶
set fileRef to open for access POSIX file outputPath with write permission
write recognizedText to fileRef as Â«class utf8Â»
close access fileRef

return recognizedText
`;

      await execAsync(`osascript -l AppleScriptObjC -e '${appleScript.replace(/'/g, "'\\''")}'`, {
        timeout: 30000,
        maxBuffer: 10 * 1024 * 1024,
      });

      // è¯»å–ç»“æœ
      if (existsSync(tempOutputPath)) {
        const text = readFileSync(tempOutputPath, 'utf-8').trim();
        console.log(`[OCR] âœ“ macOS Vision OCR æˆåŠŸï¼Œè¯†åˆ« ${text.length} å­—ç¬¦`);
        return { text, confidence: 0.9 };
      }

      return { text: '', confidence: 0 };
    } catch (error: any) {
      console.warn('[OCR] AppleScript Vision OCR failed:', error.message?.slice(0, 200));

      // æ–¹æ¡ˆ 2: ä½¿ç”¨ screencapture + Vision (æ›´ç®€å•ä½†éœ€è¦æ˜¾ç¤ºå›¾ç‰‡)
      // è·³è¿‡ï¼Œå› ä¸ºéœ€è¦é¢å¤–äº¤äº’

      // æ–¹æ¡ˆ 3: è¿”å›ç©ºç»“æœï¼Œè®©è°ƒç”¨æ–¹å›é€€åˆ° Vision API
      console.log('[OCR] macOS ç³»ç»Ÿ OCR å¤±è´¥ï¼Œå¯ä»¥é…ç½® Vision API ä½œä¸ºå¤‡é€‰');
      return { text: '', confidence: 0 };
    } finally {
      // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
      try { if (existsSync(tempImagePath)) unlinkSync(tempImagePath); } catch {}
      try { if (existsSync(tempOutputPath)) unlinkSync(tempOutputPath); } catch {}
    }
  }

  private async recognizeWindows(imageBuffer: Buffer): Promise<{ text: string; confidence: number }> {
    const { execSync } = await import('child_process');
    const { writeFileSync, unlinkSync } = await import('fs');
    const { join } = await import('path');
    const { tmpdir } = await import('os');

    const tempPath = join(tmpdir(), `hawkeye_ocr_${Date.now()}.png`);
    writeFileSync(tempPath, imageBuffer);

    try {
      // ä½¿ç”¨ Windows OCR API (é€šè¿‡ PowerShell)
      const script = `
        Add-Type -AssemblyName System.Runtime.WindowsRuntime
        $null = [Windows.Media.Ocr.OcrEngine, Windows.Foundation, ContentType=WindowsRuntime]
        $null = [Windows.Graphics.Imaging.BitmapDecoder, Windows.Foundation, ContentType=WindowsRuntime]

        $file = [Windows.Storage.StorageFile]::GetFileFromPathAsync("${tempPath.replace(/\\/g, '\\\\')}").GetAwaiter().GetResult()
        $stream = $file.OpenAsync([Windows.Storage.FileAccessMode]::Read).GetAwaiter().GetResult()
        $decoder = [Windows.Graphics.Imaging.BitmapDecoder]::CreateAsync($stream).GetAwaiter().GetResult()
        $bitmap = $decoder.GetSoftwareBitmapAsync().GetAwaiter().GetResult()

        $engine = [Windows.Media.Ocr.OcrEngine]::TryCreateFromUserProfileLanguages()
        $result = $engine.RecognizeAsync($bitmap).GetAwaiter().GetResult()

        Write-Output $result.Text
      `;

      const result = execSync(`powershell -Command "${script}"`, {
        encoding: 'utf-8',
        timeout: 30000,
      });

      return { text: result.trim(), confidence: 0.85 };
    } catch {
      return { text: '', confidence: 0 };
    } finally {
      try { unlinkSync(tempPath); } catch {}
    }
  }

  async terminate(): Promise<void> {
    // æ— éœ€æ¸…ç†
  }
}

// ============ å¤§æ¨¡å‹è§†è§‰ API åç«¯ ============

/**
 * å¤§æ¨¡å‹è§†è§‰ API åç«¯
 * ä½¿ç”¨ Gemini/Claude/GPT-4V ç­‰å¤§æ¨¡å‹çš„è§†è§‰èƒ½åŠ›
 * éœ€è¦åœ¨ AI Manager ä¸­é…ç½® API
 */
export class VisionAPIBackend implements IOCRBackend {
  readonly name = 'vision-api';
  private analyzeFunction: ((imageBase64: string) => Promise<string>) | null = null;

  get isAvailable(): boolean {
    return this.analyzeFunction !== null;
  }

  /**
   * è®¾ç½®åˆ†æå‡½æ•°ï¼ˆç”± AI Manager æ³¨å…¥ï¼‰
   */
  setAnalyzeFunction(fn: (imageBase64: string) => Promise<string>): void {
    this.analyzeFunction = fn;
  }

  async initialize(): Promise<void> {
    if (!this.analyzeFunction) {
      throw new Error('Vision API æœªé…ç½®ã€‚è¯·å…ˆè®¾ç½® AI Managerã€‚');
    }
  }

  async recognize(imageData: string | Buffer): Promise<OCRResult> {
    if (!this.analyzeFunction) {
      throw new Error('Vision API æœªé…ç½®');
    }

    const startTime = Date.now();

    const base64 = typeof imageData === 'string'
      ? imageData
      : imageData.toString('base64');

    const text = await this.analyzeFunction(base64);

    return {
      text,
      confidence: 0.95,  // å¤§æ¨¡å‹é€šå¸¸å¾ˆå‡†ç¡®
      regions: [{
        text,
        confidence: 0.95,
        bbox: [0, 0, 0, 0],
      }],
      duration: Date.now() - startTime,
      backend: 'vision-api',
    };
  }

  async terminate(): Promise<void> {
    this.analyzeFunction = null;
  }
}

// ============ OCR ç®¡ç†å™¨ ============

export class OCRManager extends EventEmitter {
  private config: OCRConfig;
  private backends: Map<OCRBackend, IOCRBackend> = new Map();
  private activeBackend: IOCRBackend | null = null;

  constructor(config: Partial<OCRConfig> = {}) {
    super();
    this.config = {
      backend: 'auto',
      languages: ['zh-Hans', 'zh-Hant', 'en'],
      confidenceThreshold: 0.5,
      useGPU: false,
      ...config,
    };
  }

  /**
   * åˆå§‹åŒ– OCR
   */
  async initialize(): Promise<void> {
    // æ³¨å†Œæ‰€æœ‰åç«¯
    this.backends.set('paddle', new PaddleOCRBackend(this.config));
    this.backends.set('system', new SystemOCRBackend());
    this.backends.set('vision-api', new VisionAPIBackend());

    // é€‰æ‹©åç«¯
    if (this.config.backend === 'auto') {
      await this.autoSelectBackend();
    } else {
      await this.selectBackend(this.config.backend);
    }

    this.emit('initialized', this.activeBackend?.name);
  }

  /**
   * è‡ªåŠ¨é€‰æ‹©æœ€ä½³åç«¯
   * ä¼˜å…ˆçº§: Vision API > ç³»ç»Ÿ OCR > PaddleOCR
   * Vision API ä½¿ç”¨å·²é…ç½®çš„äº‘ç«¯ AIï¼Œæœ€ç¨³å®šå¯é 
   */
  private async autoSelectBackend(): Promise<void> {
    // ä¼˜å…ˆä½¿ç”¨ç³»ç»Ÿ OCRï¼ˆmacOS Vision / Windows OCRï¼‰- å…è´¹ã€å¿«é€Ÿã€ç¦»çº¿
    // å…¶æ¬¡ä½¿ç”¨ Vision APIï¼ˆæ¶ˆè€— API é¢åº¦ï¼‰
    // æœ€åä½¿ç”¨ PaddleOCRï¼ˆéœ€è¦é¢å¤–å®‰è£…ï¼‰
    const priorities: OCRBackend[] = ['system', 'vision-api', 'paddle'];

    console.log('[OCR] å¼€å§‹è‡ªåŠ¨é€‰æ‹© OCR åç«¯...');

    for (const backend of priorities) {
      try {
        console.log(`[OCR] å°è¯•åç«¯: ${backend}`);
        await this.selectBackend(backend);
        console.log(`[OCR] âœ“ æˆåŠŸé€‰æ‹©åç«¯: ${backend}`);
        return;
      } catch (err: any) {
        console.log(`[OCR] âœ— åç«¯ ${backend} ä¸å¯ç”¨: ${err.message}`);
        continue;
      }
    }

    console.error('[OCR] âœ— æ²¡æœ‰å¯ç”¨çš„ OCR åç«¯');
    throw new Error('æ²¡æœ‰å¯ç”¨çš„ OCR åç«¯');
  }

  /**
   * é€‰æ‹©ç‰¹å®šåç«¯
   */
  async selectBackend(backend: OCRBackend): Promise<void> {
    if (backend === 'auto') {
      await this.autoSelectBackend();
      return;
    }

    const instance = this.backends.get(backend);
    if (!instance) {
      throw new Error(`æœªçŸ¥çš„ OCR åç«¯: ${backend}`);
    }

    await instance.initialize();
    this.activeBackend = instance;
    this.emit('backend-changed', backend);
  }

  /**
   * æ‰§è¡Œ OCR è¯†åˆ«
   */
  async recognize(imageData: string | Buffer): Promise<OCRResult> {
    if (!this.activeBackend) {
      throw new Error('OCR æœªåˆå§‹åŒ–');
    }

    // æ—¥å¿—ï¼šè¾“å…¥ä¿¡æ¯
    const inputSize = typeof imageData === 'string'
      ? imageData.length
      : imageData.length;
    const inputType = typeof imageData === 'string' ? 'base64' : 'buffer';
    const startTime = Date.now();

    console.log(`\n[OCR] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•`);
    console.log(`[OCR] ğŸ” å¼€å§‹ OCR è¯†åˆ«`);
    console.log(`[OCR] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`);
    console.log(`[OCR] æ—¶é—´: ${new Date().toISOString()}`);
    console.log(`[OCR] è¾“å…¥ç±»å‹: ${inputType}`);
    console.log(`[OCR] è¾“å…¥å¤§å°: ${(inputSize / 1024).toFixed(2)} KB`);
    console.log(`[OCR] ä½¿ç”¨åç«¯: ${this.activeBackend.name}`);
    console.log(`[OCR] ç½®ä¿¡åº¦é˜ˆå€¼: ${(this.config.confidenceThreshold * 100).toFixed(0)}%`);
    console.log(`[OCR] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`);
    console.log(`[OCR] ğŸ“¤ å‘é€å›¾ç‰‡æ•°æ®åˆ° ${this.activeBackend.name}...`);

    const result = await this.activeBackend.recognize(imageData);

    // è¿‡æ»¤ä½ç½®ä¿¡åº¦ç»“æœ
    const originalRegionCount = result.regions.length;
    result.regions = result.regions.filter(
      r => r.confidence >= this.config.confidenceThreshold * 100
    );
    const filteredCount = originalRegionCount - result.regions.length;

    // æ—¥å¿—ï¼šè¾“å‡ºä¿¡æ¯
    console.log(`[OCR] ğŸ“¥ æ”¶åˆ°è¯†åˆ«ç»“æœ`);
    console.log(`[OCR] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`);
    console.log(`[OCR] âœ… è¯†åˆ«å®Œæˆ`);
    console.log(`[OCR] æ€»è€—æ—¶: ${result.duration} ms`);
    console.log(`[OCR] å¹³å‡ç½®ä¿¡åº¦: ${result.confidence.toFixed(2)}%`);
    console.log(`[OCR] æ£€æµ‹åŒºåŸŸ: ${originalRegionCount} ä¸ª (è¿‡æ»¤å: ${result.regions.length} ä¸ª)`);
    if (filteredCount > 0) {
      console.log(`[OCR] ä½ç½®ä¿¡åº¦è¿‡æ»¤: ${filteredCount} ä¸ªåŒºåŸŸè¢«è¿‡æ»¤`);
    }
    console.log(`[OCR] æ–‡æœ¬æ€»é•¿åº¦: ${result.text.length} å­—ç¬¦`);
    console.log(`[OCR] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`);
    console.log(`[OCR] ğŸ“ è¯†åˆ«æ–‡æœ¬å†…å®¹:`);
    console.log(`[OCR] ${result.text.slice(0, 800)}${result.text.length > 800 ? '\n[OCR] ... (æ›´å¤šå†…å®¹å·²çœç•¥)' : ''}`);
    console.log(`[OCR] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n`);

    this.emit('recognized', result);
    return result;
  }

  /**
   * è®¾ç½® Vision API åˆ†æå‡½æ•°
   */
  setVisionAnalyzer(fn: (imageBase64: string) => Promise<string>): void {
    const visionBackend = this.backends.get('vision-api') as VisionAPIBackend;
    if (visionBackend) {
      visionBackend.setAnalyzeFunction(fn);
    }
  }

  /**
   * è·å–å½“å‰åç«¯
   */
  getCurrentBackend(): string | null {
    return this.activeBackend?.name ?? null;
  }

  /**
   * è·å–å¯ç”¨åç«¯åˆ—è¡¨
   */
  getAvailableBackends(): string[] {
    return [...this.backends.entries()]
      .filter(([_, backend]) => backend.isAvailable)
      .map(([name, _]) => name);
  }

  /**
   * æ¸…ç†èµ„æº
   */
  async terminate(): Promise<void> {
    for (const backend of this.backends.values()) {
      await backend.terminate();
    }
    this.backends.clear();
    this.activeBackend = null;
    this.emit('terminated');
  }
}

// å¯¼å‡ºé»˜è®¤å®ä¾‹
export const ocrManager = new OCRManager();
