/**
 * OCR æ¨¡å—
 * æ”¯æŒå¤šç§ OCR åç«¯:
 * 1. PaddleOCR (æœ¬åœ°è½»é‡çº§ ONNX æ¨¡å‹)
 * 2. å¤§æ¨¡å‹è§†è§‰ API (Gemini/Claude/GPT-4V)
 * 3. ç³»ç»ŸåŸç”Ÿ OCR (macOS Vision, Windows OCR)
 */

import { EventEmitter } from 'events';

// ============ ç±»å‹å®šä¹‰ ============

export interface OCRConfig {
  /** OCR åç«¯ç±»å‹ */
  backend: OCRBackend;
  /** è¯†åˆ«è¯­è¨€ */
  languages: string[];
  /** ç½®ä¿¡åº¦é˜ˆå€¼ (0-1) */
  confidenceThreshold: number;
  /** æ˜¯å¦å¯ç”¨ GPU åŠ é€Ÿ */
  useGPU: boolean;
}

export type OCRBackend =
  | 'paddle'      // PaddleOCR (æ¨èï¼Œè½»é‡çº§æœ¬åœ°)
  | 'vision-api'  // å¤§æ¨¡å‹è§†è§‰ API
  | 'system'      // ç³»ç»ŸåŸç”Ÿ OCR
  | 'auto';       // è‡ªåŠ¨é€‰æ‹©æœ€ä½³åç«¯

export interface OCRResult {
  /** è¯†åˆ«çš„å…¨éƒ¨æ–‡æœ¬ */
  text: string;
  /** ç½®ä¿¡åº¦ (0-100) */
  confidence: number;
  /** æ–‡æœ¬åŒºåŸŸ */
  regions: OCRRegion[];
  /** å¤„ç†è€—æ—¶ (ms) */
  duration: number;
  /** ä½¿ç”¨çš„åç«¯ */
  backend: OCRBackend;
}

export interface OCRRegion {
  /** æ–‡æœ¬å†…å®¹ */
  text: string;
  /** ç½®ä¿¡åº¦ */
  confidence: number;
  /** è¾¹ç•Œæ¡† [x, y, width, height] */
  bbox: [number, number, number, number];
  /** å¤šè¾¹å½¢é¡¶ç‚¹ï¼ˆå¦‚æœå¯ç”¨ï¼‰*/
  polygon?: [number, number][];
}

// ============ OCR åç«¯æ¥å£ ============

export interface IOCRBackend {
  readonly name: string;
  readonly isAvailable: boolean;

  initialize(): Promise<void>;
  recognize(imageData: string | Buffer): Promise<OCRResult>;
  terminate(): Promise<void>;
}

// ============ PaddleOCR åç«¯ ============

/**
 * PaddleOCR åç«¯
 *
 * æ”¯æŒå¤šç§å®‰è£…æ–¹å¼:
 * 1. @paddlejs-models/ocr (å®˜æ–¹ Paddle.jsï¼Œæµè§ˆå™¨/Node.js)
 * 2. paddleocr (Python ç‰ˆï¼Œé€šè¿‡ child_process è°ƒç”¨)
 * 3. PaddleOCR MCP Server (å¯é›†æˆåˆ° Claude Desktop)
 *
 * è½»é‡çº§ï¼Œæ”¯æŒ 100+ è¯­è¨€ï¼Œå®Œå…¨æœ¬åœ°è¿è¡Œ
 * å®˜æ–¹æ–‡æ¡£: https://github.com/PaddlePaddle/PaddleOCR
 */
export class PaddleOCRBackend implements IOCRBackend {
  readonly name = 'paddle';
  private ocr: any = null;
  private config: OCRConfig;
  private mode: 'paddlejs' | 'python' | 'none' = 'none';

  constructor(config: OCRConfig) {
    this.config = config;
  }

  get isAvailable(): boolean {
    return this.mode !== 'none';
  }

  async initialize(): Promise<void> {
    // æ–¹å¼ 1: å°è¯•ä½¿ç”¨å®˜æ–¹ @paddlejs-models/ocr
    try {
      const PaddleJS = await import('@paddlejs-models/ocr').catch(() => null);
      if (PaddleJS) {
        this.ocr = PaddleJS;
        await this.ocr.init();
        this.mode = 'paddlejs';
        console.log('âœ“ ä½¿ç”¨ Paddle.js OCR (å®˜æ–¹ JavaScript ç‰ˆæœ¬)');
        return;
      }
    } catch {
      // ç»§ç»­å°è¯•å…¶ä»–æ–¹å¼
    }

    // æ–¹å¼ 2: å°è¯•é€šè¿‡ Python è°ƒç”¨ paddleocr
    try {
      const { execSync } = await import('child_process');
      // æ£€æŸ¥ paddleocr æ˜¯å¦å®‰è£…
      execSync('python -c "import paddleocr"', { stdio: 'ignore' });
      this.mode = 'python';
      console.log('âœ“ ä½¿ç”¨ PaddleOCR Python ç‰ˆæœ¬');
      return;
    } catch {
      // Python ç‰ˆæœ¬ä¸å¯ç”¨
    }

    throw new Error(
      'PaddleOCR æœªå®‰è£…ã€‚è¯·é€‰æ‹©ä»¥ä¸‹æ–¹å¼ä¹‹ä¸€:\n' +
      '1. npm install @paddlejs-models/ocr (æ¨èï¼ŒJavaScript ç‰ˆæœ¬)\n' +
      '2. pip install paddleocr (Python ç‰ˆæœ¬)'
    );
  }

  async recognize(imageData: string | Buffer): Promise<OCRResult> {
    const startTime = Date.now();

    if (this.mode === 'paddlejs') {
      return this.recognizeWithPaddleJS(imageData, startTime);
    } else if (this.mode === 'python') {
      return this.recognizeWithPython(imageData, startTime);
    }

    throw new Error('PaddleOCR æœªåˆå§‹åŒ–');
  }

  private async recognizeWithPaddleJS(
    imageData: string | Buffer,
    startTime: number
  ): Promise<OCRResult> {
    // Paddle.js éœ€è¦ Canvas/Imageï¼Œåœ¨ Node.js ç¯å¢ƒéœ€è¦ node-canvas
    const base64 = typeof imageData === 'string'
      ? imageData
      : imageData.toString('base64');

    // åˆ›å»º Image å¯¹è±¡ï¼ˆéœ€è¦ node-canvas æˆ–åœ¨æµè§ˆå™¨ç¯å¢ƒï¼‰
    const result = await this.ocr.recognize(base64);

    const regions: OCRRegion[] = (result || []).map((item: any) => ({
      text: item.text || '',
      confidence: (item.confidence || 0) * 100,
      bbox: item.box ? [
        Math.min(...item.box.map((p: number[]) => p[0])),
        Math.min(...item.box.map((p: number[]) => p[1])),
        Math.max(...item.box.map((p: number[]) => p[0])) - Math.min(...item.box.map((p: number[]) => p[0])),
        Math.max(...item.box.map((p: number[]) => p[1])) - Math.min(...item.box.map((p: number[]) => p[1])),
      ] as [number, number, number, number] : [0, 0, 0, 0],
      polygon: item.box,
    }));

    const fullText = regions.map(r => r.text).join('\n');
    const avgConfidence = regions.length > 0
      ? regions.reduce((sum, r) => sum + r.confidence, 0) / regions.length
      : 0;

    return {
      text: fullText,
      confidence: avgConfidence,
      regions,
      duration: Date.now() - startTime,
      backend: 'paddle',
    };
  }

  private async recognizeWithPython(
    imageData: string | Buffer,
    startTime: number
  ): Promise<OCRResult> {
    const { execSync } = await import('child_process');
    const { writeFileSync, unlinkSync, readFileSync } = await import('fs');
    const { join } = await import('path');
    const { tmpdir } = await import('os');

    const buffer = typeof imageData === 'string'
      ? Buffer.from(imageData, 'base64')
      : imageData;

    const inputPath = join(tmpdir(), `hawkeye_ocr_in_${Date.now()}.png`);
    const outputPath = join(tmpdir(), `hawkeye_ocr_out_${Date.now()}.json`);

    writeFileSync(inputPath, buffer);

    try {
      // è°ƒç”¨ PaddleOCR Python API
      const pythonScript = `
import json
from paddleocr import PaddleOCR

ocr = PaddleOCR(use_angle_cls=True, lang='ch', show_log=False)
result = ocr.ocr('${inputPath}', cls=True)

output = []
if result and result[0]:
    for line in result[0]:
        box, (text, confidence) = line
        output.append({
            'box': box,
            'text': text,
            'confidence': confidence
        })

with open('${outputPath}', 'w', encoding='utf-8') as f:
    json.dump(output, f, ensure_ascii=False)
`;

      execSync(`python -c "${pythonScript.replace(/"/g, '\\"').replace(/\n/g, ';')}"`, {
        timeout: 30000,
        encoding: 'utf-8',
      });

      const resultJson = JSON.parse(readFileSync(outputPath, 'utf-8'));

      const regions: OCRRegion[] = resultJson.map((item: any) => ({
        text: item.text,
        confidence: item.confidence * 100,
        bbox: [
          Math.min(...item.box.map((p: number[]) => p[0])),
          Math.min(...item.box.map((p: number[]) => p[1])),
          Math.max(...item.box.map((p: number[]) => p[0])) - Math.min(...item.box.map((p: number[]) => p[0])),
          Math.max(...item.box.map((p: number[]) => p[1])) - Math.min(...item.box.map((p: number[]) => p[1])),
        ] as [number, number, number, number],
        polygon: item.box,
      }));

      const fullText = regions.map(r => r.text).join('\n');
      const avgConfidence = regions.length > 0
        ? regions.reduce((sum, r) => sum + r.confidence, 0) / regions.length
        : 0;

      return {
        text: fullText,
        confidence: avgConfidence,
        regions,
        duration: Date.now() - startTime,
        backend: 'paddle',
      };
    } finally {
      try { unlinkSync(inputPath); } catch {}
      try { unlinkSync(outputPath); } catch {}
    }
  }

  async terminate(): Promise<void> {
    this.ocr = null;
    this.mode = 'none';
  }
}

// ============ ç³»ç»ŸåŸç”Ÿ OCR åç«¯ ============

/**
 * ç³»ç»ŸåŸç”Ÿ OCR (macOS Vision / Windows OCR)
 * é›¶ä¾èµ–ï¼Œä½¿ç”¨ç³»ç»Ÿå†…ç½®çš„ OCR èƒ½åŠ›
 */
export class SystemOCRBackend implements IOCRBackend {
  readonly name = 'system';
  private platform: NodeJS.Platform;

  constructor() {
    this.platform = process.platform;
  }

  get isAvailable(): boolean {
    return this.platform === 'darwin' || this.platform === 'win32';
  }

  async initialize(): Promise<void> {
    // ç³»ç»Ÿ OCR æ— éœ€åˆå§‹åŒ–
  }

  async recognize(imageData: string | Buffer): Promise<OCRResult> {
    const startTime = Date.now();

    const buffer = typeof imageData === 'string'
      ? Buffer.from(imageData, 'base64')
      : imageData;

    let result: { text: string; confidence: number };

    if (this.platform === 'darwin') {
      result = await this.recognizeMacOS(buffer);
    } else if (this.platform === 'win32') {
      result = await this.recognizeWindows(buffer);
    } else {
      throw new Error(`ç³»ç»Ÿ OCR ä¸æ”¯æŒ ${this.platform} å¹³å°`);
    }

    return {
      text: result.text,
      confidence: result.confidence,
      regions: [{
        text: result.text,
        confidence: result.confidence,
        bbox: [0, 0, 0, 0],
      }],
      duration: Date.now() - startTime,
      backend: 'system',
    };
  }

  private async recognizeMacOS(imageBuffer: Buffer): Promise<{ text: string; confidence: number }> {
    const { execSync } = await import('child_process');
    const { writeFileSync, unlinkSync } = await import('fs');
    const { join } = await import('path');
    const { tmpdir } = await import('os');

    // ä¿å­˜ä¸´æ—¶æ–‡ä»¶
    const tempPath = join(tmpdir(), `hawkeye_ocr_${Date.now()}.png`);
    writeFileSync(tempPath, imageBuffer);

    try {
      // ä½¿ç”¨ macOS Vision Framework çš„å‘½ä»¤è¡Œå·¥å…·
      const script = `
        import Vision
        import Foundation

        let url = URL(fileURLWithPath: "${tempPath}")
        guard let image = CGImageSourceCreateWithURL(url as CFURL, nil),
              let cgImage = CGImageSourceCreateImageAtIndex(image, 0, nil) else {
            exit(1)
        }

        let request = VNRecognizeTextRequest()
        request.recognitionLevel = .accurate
        request.recognitionLanguages = ["zh-Hans", "zh-Hant", "en-US"]

        let handler = VNImageRequestHandler(cgImage: cgImage)
        try? handler.perform([request])

        var output = ""
        if let observations = request.results {
            for observation in observations {
                if let candidate = observation.topCandidates(1).first {
                    output += candidate.string + "\\n"
                }
            }
        }
        print(output)
      `;

      // ä½¿ç”¨ swift å‘½ä»¤æ‰§è¡Œ
      const result = execSync(`swift -e '${script.replace(/'/g, "\\'")}'`, {
        encoding: 'utf-8',
        timeout: 30000,
      });

      return { text: result.trim(), confidence: 0.9 };
    } catch (error) {
      // å¦‚æœ swift ä¸å¯ç”¨ï¼Œå°è¯•ä½¿ç”¨ shortcuts å‘½ä»¤
      try {
        // macOS 12+ å¯ä»¥ä½¿ç”¨ shortcuts è¿è¡Œé¢„è®¾çš„ OCR å¿«æ·æ–¹å¼
        const result = execSync(
          `shortcuts run "Extract Text from Image" -i "${tempPath}"`,
          { encoding: 'utf-8', timeout: 30000 }
        );
        return { text: result.trim(), confidence: 0.85 };
      } catch {
        return { text: '', confidence: 0 };
      }
    } finally {
      try { unlinkSync(tempPath); } catch {}
    }
  }

  private async recognizeWindows(imageBuffer: Buffer): Promise<{ text: string; confidence: number }> {
    const { execSync } = await import('child_process');
    const { writeFileSync, unlinkSync } = await import('fs');
    const { join } = await import('path');
    const { tmpdir } = await import('os');

    const tempPath = join(tmpdir(), `hawkeye_ocr_${Date.now()}.png`);
    writeFileSync(tempPath, imageBuffer);

    try {
      // ä½¿ç”¨ Windows OCR API (é€šè¿‡ PowerShell)
      const script = `
        Add-Type -AssemblyName System.Runtime.WindowsRuntime
        $null = [Windows.Media.Ocr.OcrEngine, Windows.Foundation, ContentType=WindowsRuntime]
        $null = [Windows.Graphics.Imaging.BitmapDecoder, Windows.Foundation, ContentType=WindowsRuntime]

        $file = [Windows.Storage.StorageFile]::GetFileFromPathAsync("${tempPath.replace(/\\/g, '\\\\')}").GetAwaiter().GetResult()
        $stream = $file.OpenAsync([Windows.Storage.FileAccessMode]::Read).GetAwaiter().GetResult()
        $decoder = [Windows.Graphics.Imaging.BitmapDecoder]::CreateAsync($stream).GetAwaiter().GetResult()
        $bitmap = $decoder.GetSoftwareBitmapAsync().GetAwaiter().GetResult()

        $engine = [Windows.Media.Ocr.OcrEngine]::TryCreateFromUserProfileLanguages()
        $result = $engine.RecognizeAsync($bitmap).GetAwaiter().GetResult()

        Write-Output $result.Text
      `;

      const result = execSync(`powershell -Command "${script}"`, {
        encoding: 'utf-8',
        timeout: 30000,
      });

      return { text: result.trim(), confidence: 0.85 };
    } catch {
      return { text: '', confidence: 0 };
    } finally {
      try { unlinkSync(tempPath); } catch {}
    }
  }

  async terminate(): Promise<void> {
    // æ— éœ€æ¸…ç†
  }
}

// ============ å¤§æ¨¡å‹è§†è§‰ API åç«¯ ============

/**
 * å¤§æ¨¡å‹è§†è§‰ API åç«¯
 * ä½¿ç”¨ Gemini/Claude/GPT-4V ç­‰å¤§æ¨¡å‹çš„è§†è§‰èƒ½åŠ›
 * éœ€è¦åœ¨ AI Manager ä¸­é…ç½® API
 */
export class VisionAPIBackend implements IOCRBackend {
  readonly name = 'vision-api';
  private analyzeFunction: ((imageBase64: string) => Promise<string>) | null = null;

  get isAvailable(): boolean {
    return this.analyzeFunction !== null;
  }

  /**
   * è®¾ç½®åˆ†æå‡½æ•°ï¼ˆç”± AI Manager æ³¨å…¥ï¼‰
   */
  setAnalyzeFunction(fn: (imageBase64: string) => Promise<string>): void {
    this.analyzeFunction = fn;
  }

  async initialize(): Promise<void> {
    if (!this.analyzeFunction) {
      throw new Error('Vision API æœªé…ç½®ã€‚è¯·å…ˆè®¾ç½® AI Managerã€‚');
    }
  }

  async recognize(imageData: string | Buffer): Promise<OCRResult> {
    if (!this.analyzeFunction) {
      throw new Error('Vision API æœªé…ç½®');
    }

    const startTime = Date.now();

    const base64 = typeof imageData === 'string'
      ? imageData
      : imageData.toString('base64');

    const text = await this.analyzeFunction(base64);

    return {
      text,
      confidence: 0.95,  // å¤§æ¨¡å‹é€šå¸¸å¾ˆå‡†ç¡®
      regions: [{
        text,
        confidence: 0.95,
        bbox: [0, 0, 0, 0],
      }],
      duration: Date.now() - startTime,
      backend: 'vision-api',
    };
  }

  async terminate(): Promise<void> {
    this.analyzeFunction = null;
  }
}

// ============ OCR ç®¡ç†å™¨ ============

export class OCRManager extends EventEmitter {
  private config: OCRConfig;
  private backends: Map<OCRBackend, IOCRBackend> = new Map();
  private activeBackend: IOCRBackend | null = null;

  constructor(config: Partial<OCRConfig> = {}) {
    super();
    this.config = {
      backend: 'auto',
      languages: ['zh-Hans', 'zh-Hant', 'en'],
      confidenceThreshold: 0.5,
      useGPU: false,
      ...config,
    };
  }

  /**
   * åˆå§‹åŒ– OCR
   */
  async initialize(): Promise<void> {
    // æ³¨å†Œæ‰€æœ‰åç«¯
    this.backends.set('paddle', new PaddleOCRBackend(this.config));
    this.backends.set('system', new SystemOCRBackend());
    this.backends.set('vision-api', new VisionAPIBackend());

    // é€‰æ‹©åç«¯
    if (this.config.backend === 'auto') {
      await this.autoSelectBackend();
    } else {
      await this.selectBackend(this.config.backend);
    }

    this.emit('initialized', this.activeBackend?.name);
  }

  /**
   * è‡ªåŠ¨é€‰æ‹©æœ€ä½³åç«¯
   * ä¼˜å…ˆçº§: PaddleOCR > ç³»ç»Ÿ OCR > Vision API
   */
  private async autoSelectBackend(): Promise<void> {
    const priorities: OCRBackend[] = ['paddle', 'system', 'vision-api'];

    for (const backend of priorities) {
      try {
        await this.selectBackend(backend);
        return;
      } catch {
        continue;
      }
    }

    throw new Error('æ²¡æœ‰å¯ç”¨çš„ OCR åç«¯');
  }

  /**
   * é€‰æ‹©ç‰¹å®šåç«¯
   */
  async selectBackend(backend: OCRBackend): Promise<void> {
    if (backend === 'auto') {
      await this.autoSelectBackend();
      return;
    }

    const instance = this.backends.get(backend);
    if (!instance) {
      throw new Error(`æœªçŸ¥çš„ OCR åç«¯: ${backend}`);
    }

    await instance.initialize();
    this.activeBackend = instance;
    this.emit('backend-changed', backend);
  }

  /**
   * æ‰§è¡Œ OCR è¯†åˆ«
   */
  async recognize(imageData: string | Buffer): Promise<OCRResult> {
    if (!this.activeBackend) {
      throw new Error('OCR æœªåˆå§‹åŒ–');
    }

    // æ—¥å¿—ï¼šè¾“å…¥ä¿¡æ¯
    const inputSize = typeof imageData === 'string'
      ? imageData.length
      : imageData.length;
    const inputType = typeof imageData === 'string' ? 'base64' : 'buffer';
    const startTime = Date.now();

    console.log(`\n[OCR] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•`);
    console.log(`[OCR] ğŸ” å¼€å§‹ OCR è¯†åˆ«`);
    console.log(`[OCR] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`);
    console.log(`[OCR] æ—¶é—´: ${new Date().toISOString()}`);
    console.log(`[OCR] è¾“å…¥ç±»å‹: ${inputType}`);
    console.log(`[OCR] è¾“å…¥å¤§å°: ${(inputSize / 1024).toFixed(2)} KB`);
    console.log(`[OCR] ä½¿ç”¨åç«¯: ${this.activeBackend.name}`);
    console.log(`[OCR] ç½®ä¿¡åº¦é˜ˆå€¼: ${(this.config.confidenceThreshold * 100).toFixed(0)}%`);
    console.log(`[OCR] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`);
    console.log(`[OCR] ğŸ“¤ å‘é€å›¾ç‰‡æ•°æ®åˆ° ${this.activeBackend.name}...`);

    const result = await this.activeBackend.recognize(imageData);

    // è¿‡æ»¤ä½ç½®ä¿¡åº¦ç»“æœ
    const originalRegionCount = result.regions.length;
    result.regions = result.regions.filter(
      r => r.confidence >= this.config.confidenceThreshold * 100
    );
    const filteredCount = originalRegionCount - result.regions.length;

    // æ—¥å¿—ï¼šè¾“å‡ºä¿¡æ¯
    console.log(`[OCR] ğŸ“¥ æ”¶åˆ°è¯†åˆ«ç»“æœ`);
    console.log(`[OCR] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`);
    console.log(`[OCR] âœ… è¯†åˆ«å®Œæˆ`);
    console.log(`[OCR] æ€»è€—æ—¶: ${result.duration} ms`);
    console.log(`[OCR] å¹³å‡ç½®ä¿¡åº¦: ${result.confidence.toFixed(2)}%`);
    console.log(`[OCR] æ£€æµ‹åŒºåŸŸ: ${originalRegionCount} ä¸ª (è¿‡æ»¤å: ${result.regions.length} ä¸ª)`);
    if (filteredCount > 0) {
      console.log(`[OCR] ä½ç½®ä¿¡åº¦è¿‡æ»¤: ${filteredCount} ä¸ªåŒºåŸŸè¢«è¿‡æ»¤`);
    }
    console.log(`[OCR] æ–‡æœ¬æ€»é•¿åº¦: ${result.text.length} å­—ç¬¦`);
    console.log(`[OCR] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`);
    console.log(`[OCR] ğŸ“ è¯†åˆ«æ–‡æœ¬å†…å®¹:`);
    console.log(`[OCR] ${result.text.slice(0, 800)}${result.text.length > 800 ? '\n[OCR] ... (æ›´å¤šå†…å®¹å·²çœç•¥)' : ''}`);
    console.log(`[OCR] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n`);

    this.emit('recognized', result);
    return result;
  }

  /**
   * è®¾ç½® Vision API åˆ†æå‡½æ•°
   */
  setVisionAnalyzer(fn: (imageBase64: string) => Promise<string>): void {
    const visionBackend = this.backends.get('vision-api') as VisionAPIBackend;
    if (visionBackend) {
      visionBackend.setAnalyzeFunction(fn);
    }
  }

  /**
   * è·å–å½“å‰åç«¯
   */
  getCurrentBackend(): string | null {
    return this.activeBackend?.name ?? null;
  }

  /**
   * è·å–å¯ç”¨åç«¯åˆ—è¡¨
   */
  getAvailableBackends(): string[] {
    return [...this.backends.entries()]
      .filter(([_, backend]) => backend.isAvailable)
      .map(([name, _]) => name);
  }

  /**
   * æ¸…ç†èµ„æº
   */
  async terminate(): Promise<void> {
    for (const backend of this.backends.values()) {
      await backend.terminate();
    }
    this.backends.clear();
    this.activeBackend = null;
    this.emit('terminated');
  }
}

// å¯¼å‡ºé»˜è®¤å®ä¾‹
export const ocrManager = new OCRManager();
